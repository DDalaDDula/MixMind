{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitsch = ['Liz', 'ÏµúÍ≥†Ï£ºÍ∞ÄÎì§Îßå ÌååÌä∏ Îòê ÎßéÏù¥ ÎÑ£ÏóàÎÑ§„Öã„Öã„Öã„ÖãÎ¶¨Ï¶à, Î†àÏù¥Îäî Í∑∏ÎÉ• ÏµúÍ≥†Ï£ºÍ∞ÄÍ∞Ä Ïä§Ïä§Î°ú ÎêòÎäî Ïàò Î∞ñÏóê ÏóÜÏúºÎ†§ÎÇò„Öã„Öã„Öã„Öã„ÖãÏä§ÌÉÄÏâΩ ÏßïÌïòÎÑ§ ÏßÑÏßú„Öã„Öã„Öã„Öã„Öã', 'Liz deserves more lines..!! why is starship unfair to Liz??!!', 'STARSHƒ∞P!!! Gƒ∞VE MORE Lƒ∞NE FOR OUR Lƒ∞Z!!!!', 'what does  it mean?', \"Can someone inform me what a 'kitsch' is?üòÇ\", 'IVEÊÑõ„Åó„Å¶„Çã\\U0001faf6', '„É™„Ç∫Ë¶öÈÜí„Åó„Å¶„Å¶„Åô„ÅçÔºÅÔºÅ', 'What a great song', 'Full Album on April 10th!!!!!', \"A music video literally never angered me more. I love these girls and it's no fault of them, but what the label is doing to this group is so shameful. Poor Liz got no screen time or lines in the song. I repeatedly saw the same girls over and over in this video while she was hidden. They couldn't try any harder to hide her, It's horrible. Someone pick this girl up under a new group so she can be allowed to shine! I'm so tired of certain girls in this group being so praised by the label while Liz is treated like a background character. It's one thing for fandoms to have favorites, but for a label to and make it so obvious is messed up. It's not even like she's bad, her voice is wonderful, she's beautiful inside and out, and her performance skills are great. She knows how to do her job! To be treated like a wall because you don't fit your labels beauty standard is disgusting. They should drop her from the label if they don't like her instead of suppressing her so she can go elsewhere. The song is great, really cool video, and the girls look and sound beautiful, but it's not fair that one of their members is treated so poorly every freaking song/performance.\", '41.038', '„ÇÅ„Å£„Å°„ÇÉËâØ„ÅÑ^^', 'so unfair, Liz deserves moreüòî', 'Î¶¨Ï¶à ÌååÌä∏ Î¨¥Ïä® ÏùºÏù¥Ïïº... Ïû•ÎÇúÌïòÏßÄ ÎßêÍ≥†;;', 'Î¶¨Ï¶àÎäî Ïôú ÌïúÎ≤àÎßå Î∂àÎü¨Ïöî?', 'ÏõêÏòÅÏù¥ Î≥¥Ïª¨Ïù¥ Îì£Í∏∞ Ìé∏ÏïàÌïú ÏÜåÎ¶¨Íµ¨ÎÇò!\\nÎπÑÏùåÎπºÎãàÍπå ÎÑàÎ¨¥ Ï¢ãÎã§. Ïù¥ÏÑúÎèÑ ÎπÑÏùåÏùÑ Ï¢Ä ÎπºÏïºÎê†ÎìØ', 'Ï≤òÏùåÏóî  Î≠êÏßÄ  ÌñàÎäîÎç∞\\nÍ≥ÑÏÜç Îì§ÏúºÎãàÍπå Ï¢ãÏïÑÏßÄÎäî ÎÖ∏Îûò', 'Rei slayed her parts', '41,015,111 M congrats IVE!!!', 'Keren', 'Very nice song', 'Â•Ω„Åç', 'holy bang bang bang‚ù§', 'They just dropped the concept photos!', 'Ni YouTube bener\" ya üò¢ udh cape\" streaming malah di apus mulu view nya üíî', 'starship distribute lines based on popularity, liz got blonde hair and opening lines as soon as she debuted meaning that starship wanted to popularize her, but obviously she took that for granted', 'I much prefer this group to New Jeans. IVE does music right.', 'yt don¬¥t delete ive views??', '√©pica', 'ame esta canci√≥n', \"Amazing as always\\nI'm so into this song! Let's go 45M\", 'Ïù¥ÏÑú ÎÑàÎ¨¥ ÏòàÏÅòÎã§', 'OOTD BITHC OOTD!!!!!!!', 'Nos estan eliminando vistas ,por eso no avanzamos \\n      P*TO  YOUTUBE (con todas las ganas de ofender , pero a la ves no XD)', 'visuaaaalll love', 'ÎÇòÎßå ÎÆ§ÎπÑ Íµ¨Î¶¨Í≤å ÎäêÍª¥ÏßÄÎÇò? Îü¨Î∏å Îã§Ïù¥Î∏å Í∞ôÏùÄ Í±∞ Î≥¥Í≥† Ïã∂ÏùÄÎç∞', 'Îß§Ïùº Îì£Í≥† ÏûàÏñ¥Ïöî\\nÎÖ∏Îûò ÎÑàÎ¨¥ Ï¢ãÎã§', \"We can't deny wonyoung's visual is a wow factor\", '0:07 „Éù„Éã„ÉÜ„Ç¶„Ç©„Éã„Éß„É≥„Éì„Ç∏„É•ËâØ„Åô„Åé', 'They knew Liz would slay if she had more lines', 'Ïûò Î≥¥Í≥† Îì§ÏóàÏäµÎãàÎã§.', '„ÅÜ„Çè„Éº„Åæ„ÅüÊù•„Åü„ÇàÁ•ûÊõ≤', 'yknow what this sounds lie? soty', 'wake up in the morning', 'I dunno but this song such a downgrade for me... Eleven and Love Dive still in my heart, After Like is 50:50', 'Starship do it so good I know what do u do like that for lizüòÇ', \"788k like >40m>ads<flop üòÖüòÖüòÖthey're only popular in Korean digital music\", 'Liz got me', 'Ya estaba en 41M youtube...üò°', 'Est√°n eliminando vistas :/', \"40M again!! YouTube! Stop it's 41M but YouTube keeps deleting it\", \"The music is quite addicted and the scene is stunning too,however,the transition of the mv seems a little bit orderless......It's kind of confusion.\", 'lets go dive!', 'felt bad for liz', 'The chorus', 'Is Liz leaving Ive?', 'love this song!!!üòçüòçüòç', 'Epic track.... all IVE tracks are epic', 'Liz ‚ù§', 'woonyoung !!!! <3', '‰ªäÂπ¥„ÇÇIVE„ÅÆÂπ¥„Å´„Åô„Çã„Åû„ÉºÔºÅ', '‰ªäÂõû„ÅÆmv„ÇÇÊúÄÈ´ò', 'ya me da miedo que todas las canciones de ive sean buenas', 'The fact that youtube kept deleting our views... we could have easily passed 45 mil by now üôÑ', '41.023', 'REI ROSITA NUNCA T VAYAS', 'go', 'Finalmente este grupito demostrando su pobre popularidad con este MV llamado chish que sacaron.\\nUna vergueza de numeros.\\nFracaso.', 'Ïû•ÏõêÏòÅ Í∞úÏù¥ÏÅòÎã§!!!!!!!!!!!‚ù§‚ù§‚ù§', 'Ïù¥ ÎÖ∏Îûò Î¶¨Ï¶à ÏùåÏÉâ Îì£Í≥†,ÍπúÏßù ÎÜÄÎû¨ÏóàÎäîÎç∞,Ï†ú Îî∏Ïù¥ ÌïúÌååÌä∏ÎùºÍ≥† ÌïòÎçîÍµ∞Ïöî.\\nÍ∑∏ ÏñòÍ∏∞Îì£Í≥†,ÎÑàÎ¨¥ ÎÜÄÎû¨Ïñ¥Ïöî.\\nÌïúÌååÌä∏ÎùºÎèÑ  Ï≤òÏùåÎì§ÏóàÎçò Ï†ú Í∑ÄÏóî Ï†úÏùº ÍΩÇÌòîÎÑ§Ïöî~', 'Í∑∏Î¶¨Í≥† Îß§ÌÅ¨Î°ú Î∞îÏù¥Îü¥ ÎåìÍ∏ÄÏù¥Îùº ÏßÄÎì§ ÏÉàÎÅº ÏïÑÏù¥ÎîîÎßå ÎãµÍ∏ÄÏúºÎ£®Îã¨Ïàò ÏûàÍ≤å Ï°∞ÏûëÌï¥ÎÜìÏùå Í∑∏Îü¨Îã§Î≥¥Îãà Ï£ÑÎã§ ÏòÅÏñ¥ÏûÑ ÏïÑÏù¥Î∏åÍ∞Ä Í∑∏Î†áÍ≤å Ìï¥Ïô∏ÏóêÏÑú Ïù∏Í∏∞Í∞Ä ÏûàÏóàÎã§Í≥†', 'go dive!', 'Can we have a 100 hours loop of Liz part please', 'Ïù¥Í±∞Î¥êÎùº Ïø†ÌÇ§ Îã¨Í≥† ÏïÑÏù¥Î∏å ÌôçÎ≥¥ÌïòÎü¨ Îã§ÎãàÎäîÍ±∞....Ïù¥Îü∞Í≤å Î∞îÎ°ú Î∞îÏù¥Îü¥ Ï£ºÏûëÏù¥ÏßÄ ÏïÑÏù¥Î∏å=Ï£ºÏûëÍ∑∏Î£π', '21th PERFECT ALL KILL\\nKitsch ‚Äì Update : #1 MelOn (=) #1 FLO (=) #1 Genie (+1) #1 Bugs (=) #1 Vibe (=) #1 Youtube (=) #1 Spotify (=) #1 Apple (=) üî•ü§≠', '41 M !!! LETS GO 50 M üê¶', \"PAK! Well deserved. I just can't stop myself from watching this 100x times a day lol\", 'ÎÖ∏ÎûòÎåÄÎ∞ïÏù¥Îã§‚ù§‚ù§‚ù§‚ù§‚ù§', '20th PERFECT ALL KILL\\nKitsch ‚Äì Update : #1 MelOn (=) #1 FLO (=) #1 Genie (+1) #1 Bugs (=)\\nüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏è', \"_From highly-anticipated returns to can't-miss debut releases, check out 15 albums dropping this April from Linkin Park, IVE, Rae Sremmurd, and more_\\n\\n- Grammy Award News\", 'ÎÖ∏Îûò Ï§ëÎèÖÏÑ±ÏûàÎã§', 'NewJeans win IVEüò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üíöüíöüíöüíöüò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£üò°ü§£ü§£üò°üò°ü§£üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üòòüò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°', 'Kakao/Melon/IVE üéâüéâüéâüéâüéâevery time IVE can be No.1üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ', '2:53 is my favorite part in this mv', 'did liz nasty', 'NewJeans win IVEüò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üòòüòòüòòüò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°üò°', 'Ï°∞ÌöåÏàò 4Ï≤ú1Î∞±Îßå ÎààÏïû...!', 'ÎÆ§ÎπÑÏÉâÍ∞êÏù¥Îûë ÏùòÏÉÅ ÏßÑÏßú Ïûò ÎΩëÏïòÎã§\\nÏä§ÌÉÄÏâΩÏù¥ Î∞∞Ïö¥ Î≥ÄÌÉú', 'Î©îÏù∏ ÌÉÄÏù¥ÌãÄÏóêÎäî Î¶¨Ï¶à ÌååÌä∏Í∞Ä ÎßéÍ∏∏......üòÆ\\u200düí®', 'Î©îÎ≥¥Í∞Ä Î©îÎ≥¥Í∞Ä ÏïÑÎãå Í∑∏Î£π', \"20th PERFECT ALL KILL\\n 'Kitsch' ‚Äì 10AM KST: \\n\\n#1 MelOn (=) \\n#1 FLO (=) \\n#1 Genie (=) \\n#1 Bugs (=) \\n\\nMelOn ULs: 398,081 (+1,163)\", 'malarda', 'Î¶¨Ï¶à ÌååÌä∏Í∞Ä ÎÑàÎ¨¥ ÏóÜÏñ¥Ïöî„Ö†„Öú', '20th PERFECT ALL KILL\\nKitsch ‚Äì Update : #1 MelOn (=) #1 FLO (=) #1 Genie (+1) #1 Bugs (=)\\nüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏èüòé‚òùÔ∏è', \"Liz's part is so short but sweet , looking forward to the full new album. I hope everyone has their proper line distribution.\", 'YUH YUH YUH YUH YUH YUH YUH', 'It looks like Liz is not part of the group anymore.', 'I LOVE REI', 'THEIR CONFIDENCE >>>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning ÏúÑÌïú review Îç∞Ïù¥ÌÑ∞\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt', header=0, delimiter='\\t' ,quoting=3)[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['document'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 02:10:18.848003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/envs/mixmind/lib/python3.8/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268f0c8b354e47cca44c92753fe7b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbc818ba93d42b9b2272c591c3edce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fe70aead7f4d80aa70baa92d4eb9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from emotion_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = '/home/cshoon036/MixMind/mm_bert/korean/vocab_9class_500.csv'\n",
    "stopwords_path = '/home/cshoon036/MixMind/mm_bert/korean/stopwords.txt'\n",
    "\n",
    "vocab = load_vocab(vocab_path, stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 20\n",
    "VALID_SPLIT = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49999 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/envs/mixmind/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49999/49999 [00:28<00:00, 1728.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 49999, # labels: 49999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data[:1000] # for test\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train[\"document\"], train[\"label\"]), total=len(train)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_sentence_input_ids = np.array(input_ids, dtype=int)\n",
    "train_sentence_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_sentence_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_sentence_inputs = (train_sentence_input_ids, train_sentence_attention_masks, train_sentence_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #Î†àÏù¥Î∏î ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Î¶¨Ïä§Ìä∏\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_sentence_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101    100    119    119    119   9928  58823  30005  11664   9757\n",
      " 118823  30858  18227 119219    119    119    119    119   9580  41605\n",
      "  25486  12310  20626  23466   8843 118986  12508   9523  17196  16439\n",
      "    102      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "[CLS] [UNK]... Ìè¨Ïä§ÌÑ∞Î≥¥Í≥† Ï¥àÎî©ÏòÅÌôîÏ§Ñ.... Ïò§Î≤ÑÏó∞Í∏∞Ï°∞Ï∞® Í∞ÄÎ≥çÏßÄ ÏïäÍµ¨ÎÇò [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "input_id = train_sentence_input_ids[1]\n",
    "attention_mask = train_sentence_attention_masks[1]\n",
    "token_type_id = train_sentence_type_ids[1]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 02:16:09.652824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-06 02:16:09.652887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mixmind-vm\n",
      "2023-04-06 02:16:09.652898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mixmind-vm\n",
      "2023-04-06 02:16:09.653167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
      "2023-04-06 02:16:09.653201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
      "2023-04-06 02:16:09.653208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
      "2023-04-06 02:16:09.653829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "loading configuration file config.json from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dfd884f37c484d8586a47ba9695370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file tf_model.h5 from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tf_model.h5\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mixmind/lib/python3.8/site-packages/tensorflow_addons/optimizers/rectified_adam.py:121: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Rectified Adam ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÇ¨Ïö©\n",
    "#!pip install tensorflow_addons\n",
    "import tensorflow_addons as tfa\n",
    "# Ï¥ù batch size * 4 epoch = 2344 * 4\n",
    "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*2, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "sentiment_model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tf2_bert_sentiment\"\n",
    "\n",
    "# overfittingÏùÑ ÎßâÍ∏∞ ÏúÑÌïú ealrystop Ï∂îÍ∞Ä\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=3)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1Î≤à Ïù¥ÏÉÅ ÏÉÅÏäπÏù¥ ÏóÜÏúºÎ©¥ Ï¢ÖÎ£å)\\\n",
    "\n",
    "checkpoint_path = os.path.join(\"./\", model_name, 'best_model')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_loss', verbose=1, mode='min' ,save_best_only=True , save_weight_only=True)\n",
    "\n",
    "# ÌïôÏäµÍ≥º eval ÏãúÏûë\n",
    "history = sentiment_model.fit(train_sentence_inputs, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ÏµúÍ≥†Ï£ºÍ∞ÄÎì§Îßå ÌååÌä∏ Îòê ÎßéÏù¥ ÎÑ£ÏóàÎÑ§„Öã„Öã„Öã„ÖãÎ¶¨Ï¶à Î†àÏù¥Îäî Í∑∏ÎÉ• ÏµúÍ≥†Ï£ºÍ∞ÄÍ∞Ä Ïä§Ïä§Î°ú ÎêòÎäî Ïàò Î∞ñÏóê ÏóÜÏúºÎ†§ÎÇò„Öã„Öã„Öã„Öã„ÖãÏä§ÌÉÄÏâΩ ÏßïÌïòÎÑ§ ÏßÑÏßú„Öã„Öã„Öã„Öã„Öã',\n",
       " 'Î¶¨Ï¶à ÌååÌä∏ Î¨¥Ïä® ÏùºÏù¥Ïïº Ïû•ÎÇúÌïòÏßÄ ÎßêÍ≥†',\n",
       " 'Î¶¨Ï¶àÎäî Ïôú ÌïúÎ≤àÎßå Î∂àÎü¨Ïöî',\n",
       " 'ÏõêÏòÅÏù¥ Î≥¥Ïª¨Ïù¥ Îì£Í∏∞ Ìé∏ÏïàÌïú ÏÜåÎ¶¨Íµ¨ÎÇò ÎπÑÏùåÎπºÎãàÍπå ÎÑàÎ¨¥ Ï¢ãÎã§ Ïù¥ÏÑúÎèÑ ÎπÑÏùåÏùÑ Ï¢Ä ÎπºÏïºÎê†ÎìØ',\n",
       " 'Ï≤òÏùåÏóî Î≠êÏßÄ ÌñàÎäîÎç∞ Í≥ÑÏÜç Îì§ÏúºÎãàÍπå Ï¢ãÏïÑÏßÄÎäî ÎÖ∏Îûò',\n",
       " 'Ïù¥ÏÑú ÎÑàÎ¨¥ ÏòàÏÅòÎã§',\n",
       " 'ÎÇòÎßå ÎÆ§ÎπÑ Íµ¨Î¶¨Í≤å ÎäêÍª¥ÏßÄÎÇò Îü¨Î∏å Îã§Ïù¥Î∏å Í∞ôÏùÄ Í±∞ Î≥¥Í≥† Ïã∂ÏùÄÎç∞',\n",
       " 'Îß§Ïùº Îì£Í≥† ÏûàÏñ¥Ïöî ÎÖ∏Îûò ÎÑàÎ¨¥ Ï¢ãÎã§',\n",
       " 'Ïûò Î≥¥Í≥† Îì§ÏóàÏäµÎãàÎã§',\n",
       " 'Ïû•ÏõêÏòÅ Í∞úÏù¥ÏÅòÎã§',\n",
       " 'Ïù¥ ÎÖ∏Îûò Î¶¨Ï¶à ÏùåÏÉâ Îì£Í≥† ÍπúÏßù ÎÜÄÎû¨ÏóàÎäîÎç∞ Ï†ú Îî∏Ïù¥ ÌïúÌååÌä∏ÎùºÍ≥† ÌïòÎçîÍµ∞Ïöî Í∑∏ ÏñòÍ∏∞Îì£Í≥† ÎÑàÎ¨¥ ÎÜÄÎû¨Ïñ¥Ïöî ÌïúÌååÌä∏ÎùºÎèÑ Ï≤òÏùåÎì§ÏóàÎçò Ï†ú Í∑ÄÏóî Ï†úÏùº ÍΩÇÌòîÎÑ§Ïöî',\n",
       " 'Í∑∏Î¶¨Í≥† Îß§ÌÅ¨Î°ú Î∞îÏù¥Îü¥ ÎåìÍ∏ÄÏù¥Îùº ÏßÄÎì§ ÏÉàÎÅº ÏïÑÏù¥ÎîîÎßå ÎãµÍ∏ÄÏúºÎ£®Îã¨Ïàò ÏûàÍ≤å Ï°∞ÏûëÌï¥ÎÜìÏùå Í∑∏Îü¨Îã§Î≥¥Îãà Ï£ÑÎã§ ÏòÅÏñ¥ÏûÑ ÏïÑÏù¥Î∏åÍ∞Ä Í∑∏Î†áÍ≤å Ìï¥Ïô∏ÏóêÏÑú Ïù∏Í∏∞Í∞Ä ÏûàÏóàÎã§Í≥†',\n",
       " 'Ïù¥Í±∞Î¥êÎùº Ïø†ÌÇ§ Îã¨Í≥† ÏïÑÏù¥Î∏å ÌôçÎ≥¥ÌïòÎü¨ Îã§ÎãàÎäîÍ±∞ Ïù¥Îü∞Í≤å Î∞îÎ°ú Î∞îÏù¥Îü¥ Ï£ºÏûëÏù¥ÏßÄ ÏïÑÏù¥Î∏å Ï£ºÏûëÍ∑∏Î£π',\n",
       " 'ÎÖ∏ÎûòÎåÄÎ∞ïÏù¥Îã§',\n",
       " 'ÎÖ∏Îûò Ï§ëÎèÖÏÑ±ÏûàÎã§',\n",
       " 'Ï°∞ÌöåÏàò Ï≤ú Î∞±Îßå ÎààÏïû',\n",
       " 'ÎÆ§ÎπÑÏÉâÍ∞êÏù¥Îûë ÏùòÏÉÅ ÏßÑÏßú Ïûò ÎΩëÏïòÎã§ Ïä§ÌÉÄÏâΩÏù¥ Î∞∞Ïö¥ Î≥ÄÌÉú',\n",
       " 'Î©îÏù∏ ÌÉÄÏù¥ÌãÄÏóêÎäî Î¶¨Ï¶à ÌååÌä∏Í∞Ä ÎßéÍ∏∏',\n",
       " 'Î©îÎ≥¥Í∞Ä Î©îÎ≥¥Í∞Ä ÏïÑÎãå Í∑∏Î£π',\n",
       " 'Î¶¨Ï¶à ÌååÌä∏Í∞Ä ÎÑàÎ¨¥ ÏóÜÏñ¥Ïöî']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kitsch_kor = []\n",
    "kitsch_kor_join = []\n",
    "\n",
    "p = re.compile('[„Ñ±-„ÖéÍ∞Ä-Ìû£]+')\n",
    "\n",
    "for i in kitsch:\n",
    "    if p.findall(i):\n",
    "        kitsch_kor.append(p.findall(i))\n",
    "\n",
    "for i in kitsch_kor:\n",
    "    kitsch_kor_join.append(\" \".join(i))\n",
    "\n",
    "kitsch_kor_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mixmind/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['5359', '5361', 0],\n",
       " [0, 0, 0],\n",
       " ['5370', '5359', '5364'],\n",
       " ['5363', '5370', '5366'],\n",
       " ['5359', '5370', '5363'],\n",
       " ['5359', '5370', '5363'],\n",
       " ['5359', '5364', '5366'],\n",
       " ['5370', '5359', '5363'],\n",
       " ['5364', '5365', '5366'],\n",
       " ['5359', 0, 0],\n",
       " ['5370', '5366', 0],\n",
       " ['5361', '5363', 0],\n",
       " ['5361', '5363', '5370'],\n",
       " ['5370', '5359', '5365'],\n",
       " ['5370', '5359', '5365'],\n",
       " ['5368', '5359', 0],\n",
       " ['5361', '5365', '5364'],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " ['5364', '5366', '5365']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion = []\n",
    "\n",
    "for i in kitsch_kor_join:\n",
    "    temp = hybrid_emotion_export_persent(temp, sentiment_model, vocab)\n",
    "    emotion.append([temp['emotion1'], temp['emotion2'], temp['emotion3']])\n",
    "\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ÏÇ¨Îûë', 'Ïó¥Ï†ï', '0'],\n",
       " ['0', '0', '0'],\n",
       " ['Ïû¨ÎØ∏', 'ÏÇ¨Îûë', 'Ïä¨Ìîî'],\n",
       " ['ÌñâÎ≥µ', 'Ïû¨ÎØ∏', 'Í≥µÌóàÌï®'],\n",
       " ['ÏÇ¨Îûë', 'Ïû¨ÎØ∏', 'ÌñâÎ≥µ'],\n",
       " ['ÏÇ¨Îûë', 'Ïû¨ÎØ∏', 'ÌñâÎ≥µ'],\n",
       " ['ÏÇ¨Îûë', 'Ïä¨Ìîî', 'Í≥µÌóàÌï®'],\n",
       " ['Ïû¨ÎØ∏', 'ÏÇ¨Îûë', 'ÌñâÎ≥µ'],\n",
       " ['Ïä¨Ìîî', 'Î∂ÑÎÖ∏', 'Í≥µÌóàÌï®'],\n",
       " ['ÏÇ¨Îûë', '0', '0'],\n",
       " ['Ïû¨ÎØ∏', 'Í≥µÌóàÌï®', '0'],\n",
       " ['Ïó¥Ï†ï', 'ÌñâÎ≥µ', '0'],\n",
       " ['Ïó¥Ï†ï', 'ÌñâÎ≥µ', 'Ïû¨ÎØ∏'],\n",
       " ['Ïû¨ÎØ∏', 'ÏÇ¨Îûë', 'Î∂ÑÎÖ∏'],\n",
       " ['Ïû¨ÎØ∏', 'ÏÇ¨Îûë', 'Î∂ÑÎÖ∏'],\n",
       " ['Í≥µÌè¨', 'ÏÇ¨Îûë', '0'],\n",
       " ['Ïó¥Ï†ï', 'Î∂ÑÎÖ∏', 'Ïä¨Ìîî'],\n",
       " ['0', '0', '0'],\n",
       " ['0', '0', '0'],\n",
       " ['Ïä¨Ìîî', 'Í≥µÌóàÌï®', 'Î∂ÑÎÖ∏']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_dict = {0:'0', '5359':'ÏÇ¨Îûë', '5370':'Ïû¨ÎØ∏', '5361':'Ïó¥Ï†ï', '5363':'ÌñâÎ≥µ', '5364':'Ïä¨Ìîî', '5365':'Î∂ÑÎÖ∏', '5366':'Í≥µÌóàÌï®', '5367':'Í∞àÎßù', '5368':'Í≥µÌè¨'}\n",
    "\n",
    "real_kitsch = []\n",
    "\n",
    "for i in emotion:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(emo_dict[j])\n",
    "    real_kitsch.append(temp)\n",
    "\n",
    "real_kitsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
