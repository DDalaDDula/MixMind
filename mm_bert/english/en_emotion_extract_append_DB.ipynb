{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01786c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re , os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lyrics_preprocessing_en import lyrics_to_corpus , sentence_preprocessing\n",
    "from lyrics_emotion_an\n",
    "tqdm.pandas()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bc6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c212a",
   "metadata": {},
   "source": [
    "### Trainformers 에 BERT-base model을 불러옵니다\n",
    "이미 다운로드 되어있음 ( 다운로드 안되어있을 경우 다운로드 실행 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875d7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048bd4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683153f4",
   "metadata": {},
   "source": [
    "### 저장된 모델 불러오기\n",
    "BERT 모델 학습결과 중 가장 좋은 모델 저장 경로를 불러와 현 모델에 weight 값 저장<br>\n",
    "학습했던 모델과 똑같은 구조를 가진 모델을 설계하고 가중치를 입혀주어야함.\n",
    "\n",
    "모델링 코드는 Bert_modeling 디렉터리에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a681df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\"./\", 'bert_save_weight/', 'multi_emotion_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d89de22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002D95A742B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002D95A742B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "# 학습모델과 똑같이 설계함\n",
    "max_len = 70\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "# embeddings = dbert_model(input_ids,attention_mask = input_mask)[0]\n",
    "\n",
    "\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 means pooler_output)\n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "\n",
    "y = Dense(6,activation = 'sigmoid')(out)\n",
    "    \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2d9011e1ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 설계했던 모델에 가중치 로드\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0829e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 에측함수\n",
    "def emotion_predict(sentence):\n",
    "    x_val = tokenizer(\n",
    "        text=sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=70,\n",
    "        truncation=True,\n",
    "        padding='max_length', \n",
    "        return_tensors='tf',\n",
    "        return_token_type_ids = False,\n",
    "        return_attention_mask = True,\n",
    "        verbose = True)\n",
    "    validation = model.predict({'input_ids':x_val['input_ids'],'attention_mask':x_val['attention_mask']})*100\n",
    "    return np.argmax(validation, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c609f95",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f727f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "#indj 데이터 베이스 config\n",
    "RDS_config = {\n",
    "    # 접속할 db 정보 입력\n",
    "}\n",
    "\n",
    "# data base connect\n",
    "indj_db = pymysql.connect(**RDS_config, cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73da9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_analysis_query = \"\"\"SELECT DISTINCT rma.music_idx, rmm.title, rmm.lyrics\n",
    "FROM RENEW_music_analytics AS rma\n",
    "LEFT JOIN RENEW_meta_music AS rmm ON rma.music_idx = rmm.music_idx\"\"\"\n",
    "\n",
    "RENEW_meta_music_query = \"\"\"SELECT DISTINCT rmm.music_idx , rmm.title , rmm.lyrics\n",
    "FROM RENEW_meta_music AS rmm\n",
    "WHERE rmm.lyrics <> 'None'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5269dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커서 객체 생성\n",
    "cursor = indj_db.cursor()\n",
    "\n",
    "# SQL 테이블을 pandas Dataframe 으로 불러오기\n",
    "sql = RENEW_meta_music_query\n",
    "cursor.execute(sql)\n",
    "res = cursor.fetchall()\n",
    "lyrics_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfa7c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글 영어 구분 : 한글 비중(%) 이상이면 한글 분류\n",
    "def isKorean_percent(input_s , percentage):\n",
    "    k_count = 0\n",
    "    e_count = 0\n",
    "    for c in input_s:\n",
    "        if ord('가') <= ord(c) <= ord('힣'):\n",
    "            k_count+=1\n",
    "        elif ord('a') <= ord(c.lower()) <= ord('z'):\n",
    "            e_count+=1\n",
    "    if k_count ==0:\n",
    "        return 0\n",
    "    else :\n",
    "        percent = k_count / (k_count + e_count)\n",
    "        return 1 if percent>percentage else 0\n",
    "\n",
    "# 타이틀에 붙어있는 MR , Inst. 필터\n",
    "def isRemoveData(title):\n",
    "    if 'inst.' in title or 'Inst.' in title:\n",
    "        return 1\n",
    "    if 'Instrumental' in title or 'instrumental' in title:\n",
    "        return 1\n",
    "    elif 'MR' in title:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882ea8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외국어 & 한국어 구분\n",
    "lyrics_df['isKorean'] = lyrics_df['lyrics'].progress_map(lambda x : isKorean_percent(x,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0c0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외국어 필터링\n",
    "en_lyrics_df = lyrics_df[lyrics_df['isKorean'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3475b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 964579/964579 [00:00<00:00, 1372072.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# 가사 길이 구하기\n",
    "en_lyrics_df['lyrics_len'] = lyrics_df['lyrics'].progress_map(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be9ef0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100자 이하 가사길이 제거\n",
    "# ex) 기타 반주곡 입니다. , 가사를 넣어주세요 등등\n",
    "en_lyrics_df = en_lyrics_df[en_lyrics_df['lyrics_len'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1c07cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect #언어 판별 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "258d3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 과정에서 \"?????\"\" 만 들어있는 문장 \"숫자\"만 있는 문장들이 제외됨.\n",
    "def language_detect(lyrics):\n",
    "    \"\"\"가사의 언어를 판별해주는 함수 언어를 판별할 수 없으면 no lan 반환\"\"\"\n",
    "    try:\n",
    "        detect_res = detect(lyrics)\n",
    "        return str(detect_res)\n",
    "    except:\n",
    "        return \"no lan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e17cb43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 443402/443402 [27:07<00:00, 272.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# 언어 판별\n",
    "en_lyrics_df['lan'] = en_lyrics_df['lyrics'].progress_map(lambda x : language_detect(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f291fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어를 제외한 나머지 언어 제거\n",
    "en_lyrics_df = en_lyrics_df[en_lyrics_df['lan'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e46ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 394514/394514 [00:00<00:00, 1368023.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# inst , MR 여부 판단\n",
    "en_lyrics_df['isInst'] = en_lyrics_df['title'].progress_map(lambda x : isRemoveData(x))\n",
    "# inst , MR 제거\n",
    "en_lyrics_df = en_lyrics_df[en_lyrics_df['isInst'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56609292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_emotion_export_persent(lyrics):\n",
    "    # 가사 전처리 진행 -> 문장 중복제거 , 특수문자 제거 , 앞뒤 공백제거 , 문장 재구성\n",
    "    corpus = sentence_preprocessing(lyrics_to_corpus(lyrics))\n",
    "    emotion_count_list = [] \n",
    "    for i in corpus:\n",
    "        # 나눠진 문장 하나씩 예측을 진행함.\n",
    "        emotion_count_list.append(emotion_predict(i)[0])\n",
    "    \n",
    "    # 예측 결과를 합산\n",
    "    emotion_count = dict(Counter(emotion_count_list).most_common(6))\n",
    "    \n",
    "    # 감정명 치환 { 놀람 0 , 사랑 1 , 즐거움 2 , 슬픔 3 , 분노 4 , 두려움 5 }\n",
    "    emotion_rename = { 0 : '5369' , 1 : '5359' , 2 : '5370', 3 : '5364' , 4: '5365' , 5: '5368'}\n",
    "    res = dict((emotion_rename[key], value) for (key, value) in emotion_count.items())\n",
    "    \n",
    "    # 예측결과를 비율(%)로 변경.\n",
    "    total = sum(res.values())\n",
    "    for emotion in list(res.keys()):\n",
    "        res[emotion] = round((res[emotion] / total),5)\n",
    "    \n",
    "    top_dict = {}\n",
    "    # 값의 크기의 따른 감정 순서 정렬( 상위 3개의 감정만 따로 뽑아주기 위함.)\n",
    "    sort_dict = dict(sorted(res.items() , key=(lambda x : x[1]),reverse = True))\n",
    "    sort_keys = list(sort_dict.keys())\n",
    "    \n",
    "       \n",
    "    # 감정의 결과가 0 개 일경우 -> 0 값으로 대체함.\n",
    "    if len(sort_dict) == 0:\n",
    "        top_dict = {'emotion1' : 0 , 'emotion2' : 0 , 'emotion3' : 0}\n",
    "    # 감정의 결과가 1개 일경우 -> 1개를 제외한 나머지를 0값으로 대체함.\n",
    "    elif len(sort_dict) == 1:\n",
    "        top_dict = {'emotion1' : sort_keys[0],'emotion2' : 0 , 'emotion3' : 0}\n",
    "    # 감정의 결과가 2개 일경우 -> 2개를 제외한 나머지를 0값으로 대체함.\n",
    "    elif len(sort_dict) == 2:\n",
    "        top_dict = {'emotion1' : sort_keys[0], 'emotion2' : sort_keys[1], 'emotion3' : 0}\n",
    "    # 감정의 결과가 3개 이상일 경우\n",
    "    else :\n",
    "        top_dict = {'emotion1' : sort_keys[0], 'emotion2' : sort_keys[1], 'emotion3' : sort_keys[2]}\n",
    "    \n",
    "    # 영어에는 없는 감정 \"0\" 값으로 추가 한국어영어 통합하기 위함\n",
    "    sort_dict['5361'] = 0 # 열정\n",
    "    sort_dict['5363'] = 0 # 행복\n",
    "    sort_dict['5366'] = 0 # 외로움\n",
    "    sort_dict['5367'] = 0 # 그리움\n",
    "    \n",
    "    sort_dict.update(top_dict)\n",
    "    \n",
    "    return sort_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ea307",
   "metadata": {},
   "source": [
    "### 미리 뽑혀진 데이터 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d9f6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커서 객체 생성\n",
    "cursor = indj_db.cursor()\n",
    "\n",
    "# SQL 테이블을 pandas Dataframe 으로 불러오기\n",
    "sql = \"\"\"SELECT * FROM `indj_service`.`RENEW_lyrics_emotion_percent`;\"\"\"\n",
    "cursor.execute(sql)\n",
    "res = cursor.fetchall()\n",
    "analysis_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e01b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 - 삽입되어진 데이터 index (차집합)\n",
    "unique_list = list(set(en_lyrics_df['music_idx'].to_list()) -  set(analysis_df['music_idx'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0fa17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# music_idx 로 index를 바꿔주고 loc 으로 이미 추출해야만 하는 데이터 필터링(삽입되어진 데이터 제외)\n",
    "en_lyrics_df = en_lyrics_df.set_index('music_idx')\n",
    "en_lyrics_df = en_lyrics_df.loc[unique_list]\n",
    "en_lyrics_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56b578",
   "metadata": {},
   "source": [
    "### 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d208b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 DataFrame 변환을 위해 dict 형태로 추출시작\n",
    "emotion_result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0dc881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████                | 38807/50000 [35:44:41<6:58:44,  2.24s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(en_lyrics_df))[20000:70000]):\n",
    "    low = en_lyrics_df.iloc[i]\n",
    "    emotion_result = multi_emotion_export_persent(low['lyrics'])\n",
    "    try:\n",
    "         # musict_idx 가 key 값 , emotion_result 가 value 값\n",
    "        emotion_result_dict[low['music_idx']] = emotion_result\n",
    "    except IndexError:\n",
    "        print(\"{}번째 idx 에러 - 가사 : {}\".format(i,low['lyrics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d75d010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_result_df = pd.DataFrame(emotion_result_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb560017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5370</th>\n",
       "      <th>5364</th>\n",
       "      <th>5368</th>\n",
       "      <th>5365</th>\n",
       "      <th>5369</th>\n",
       "      <th>5359</th>\n",
       "      <th>5361</th>\n",
       "      <th>5363</th>\n",
       "      <th>5366</th>\n",
       "      <th>5367</th>\n",
       "      <th>emotion1</th>\n",
       "      <th>emotion2</th>\n",
       "      <th>emotion3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31457282</th>\n",
       "      <td>0.52632</td>\n",
       "      <td>0.18421</td>\n",
       "      <td>0.13158</td>\n",
       "      <td>0.07895</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.02632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5370</td>\n",
       "      <td>5364</td>\n",
       "      <td>5368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31457285</th>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5364</td>\n",
       "      <td>5369</td>\n",
       "      <td>5368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505882</th>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.25926</td>\n",
       "      <td>0.14815</td>\n",
       "      <td>0.14815</td>\n",
       "      <td>0.11111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5370</td>\n",
       "      <td>5364</td>\n",
       "      <td>5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505883</th>\n",
       "      <td>0.10417</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14583</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.10417</td>\n",
       "      <td>0.02083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5364</td>\n",
       "      <td>5368</td>\n",
       "      <td>5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505884</th>\n",
       "      <td>0.10811</td>\n",
       "      <td>0.18919</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.10811</td>\n",
       "      <td>0.02703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5368</td>\n",
       "      <td>5365</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120744</th>\n",
       "      <td>0.32143</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0.21429</td>\n",
       "      <td>0.17857</td>\n",
       "      <td>0.17857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5370</td>\n",
       "      <td>5368</td>\n",
       "      <td>5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120745</th>\n",
       "      <td>0.09091</td>\n",
       "      <td>0.63636</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>0.09091</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>0.09091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5364</td>\n",
       "      <td>5370</td>\n",
       "      <td>5359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120746</th>\n",
       "      <td>0.30769</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.34615</td>\n",
       "      <td>0.11538</td>\n",
       "      <td>0.15385</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5368</td>\n",
       "      <td>5370</td>\n",
       "      <td>5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120747</th>\n",
       "      <td>0.07895</td>\n",
       "      <td>0.28947</td>\n",
       "      <td>0.31579</td>\n",
       "      <td>0.15789</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.10526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5368</td>\n",
       "      <td>5364</td>\n",
       "      <td>5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120748</th>\n",
       "      <td>0.47826</td>\n",
       "      <td>0.34783</td>\n",
       "      <td>0.04348</td>\n",
       "      <td>0.08696</td>\n",
       "      <td>0.04348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5370</td>\n",
       "      <td>5364</td>\n",
       "      <td>5365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             5370     5364     5368     5365     5369     5359 5361 5363 5366  \\\n",
       "31457282  0.52632  0.18421  0.13158  0.07895  0.05263  0.02632    0    0    0   \n",
       "31457285  0.08333  0.33333     0.25  0.08333     0.25      NaN    0    0    0   \n",
       "32505882  0.33333  0.25926  0.14815  0.14815  0.11111      NaN    0    0    0   \n",
       "32505883  0.10417      0.5  0.14583    0.125  0.10417  0.02083    0    0    0   \n",
       "32505884  0.10811  0.18919   0.2973  0.27027  0.10811  0.02703    0    0    0   \n",
       "...           ...      ...      ...      ...      ...      ...  ...  ...  ...   \n",
       "1120744   0.32143  0.10714  0.21429  0.17857  0.17857      NaN    0    0    0   \n",
       "1120745   0.09091  0.63636  0.04545  0.09091  0.04545  0.09091    0    0    0   \n",
       "1120746   0.30769  0.03846  0.34615  0.11538  0.15385  0.03846    0    0    0   \n",
       "1120747   0.07895  0.28947  0.31579  0.15789  0.05263  0.10526    0    0    0   \n",
       "1120748   0.47826  0.34783  0.04348  0.08696  0.04348      NaN    0    0    0   \n",
       "\n",
       "         5367 emotion1 emotion2 emotion3  \n",
       "31457282    0     5370     5364     5368  \n",
       "31457285    0     5364     5369     5368  \n",
       "32505882    0     5370     5364     5365  \n",
       "32505883    0     5364     5368     5365  \n",
       "32505884    0     5368     5365     5364  \n",
       "...       ...      ...      ...      ...  \n",
       "1120744     0     5370     5368     5369  \n",
       "1120745     0     5364     5370     5359  \n",
       "1120746     0     5368     5370     5369  \n",
       "1120747     0     5368     5364     5365  \n",
       "1120748     0     5370     5364     5365  \n",
       "\n",
       "[20000 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bc7bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN -> 0\n",
    "emotion_result_df = emotion_result_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85d092ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파일로 저장\n",
    "emotion_result_df.to_csv('en_emotion_data/en_210702.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78501023",
   "metadata": {},
   "source": [
    "### 데이터 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eabc1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9595/9595 [01:54<00:00, 83.45it/s]\n"
     ]
    }
   ],
   "source": [
    "indj_db = pymysql.connect(**RDS_config, cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = indj_db.cursor()\n",
    "top_emotion_data = []\n",
    "emotion_percent_data = []\n",
    "\n",
    "for i in tqdm(range(len(emotion_result_df))):\n",
    "    low = emotion_result_df.iloc[i]\n",
    "    top_emotion_values = [\n",
    "        low['emotion1'],\n",
    "        low['emotion2'],\n",
    "        low['emotion3'],\n",
    "        low.name # low index\n",
    "    ]\n",
    "    emotion_percent_values = [\n",
    "        low.name,\n",
    "        low['5359'], # 사랑\n",
    "        low['5370'], # 즐거움\n",
    "        low['5361'], # 열정\n",
    "        low['5363'], # 행복\n",
    "        low['5364'], # 슬픔\n",
    "        low['5365'], # 분노\n",
    "        low['5366'], # 외로움\n",
    "        low['5367'], # 그리움\n",
    "        low['5368'], # 두려움\n",
    "        low['5369']  # 놀람\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    top_emotion_data.append(top_emotion_values)\n",
    "    emotion_percent_data.append(emotion_percent_values)\n",
    "    \n",
    "    # 1000개의 데이터가 모일때 commit\n",
    "    if i % 1000 == 0:\n",
    "        sql_query = \"\"\"UPDATE RENEW_music_analytics \n",
    "        SET lyrics_emotion1 = %s ,lyrics_emotion2 = %s , lyrics_emotion3 = %s\n",
    "        WHERE music_idx = %s\"\"\"\n",
    "        cursor.executemany(sql_query,top_emotion_data)\n",
    "        indj_db.commit()\n",
    "        top_emotion_data = []\n",
    "        \n",
    "        sql_query2 = \"\"\"INSERT INTO RENEW_lyrics_emotion_percent\n",
    "        (music_idx , lov , joy , pas , hap , sad ,ang , lon , mis , fea , sup)\n",
    "        VALUES (%s , %s , %s , %s , %s , %s , %s, %s , %s, %s, %s)\"\"\"\n",
    "        cursor.executemany(sql_query2,emotion_percent_data)\n",
    "        indj_db.commit()\n",
    "        emotion_percent_data = []\n",
    "    \n",
    "# 나머지 데이터 수정 ( n 의 배수가 아닌 데이터)\n",
    "sql_query = \"\"\"UPDATE RENEW_music_analytics \n",
    "    SET lyrics_emotion1 = %s ,lyrics_emotion2 = %s , lyrics_emotion3 = %s\n",
    "    WHERE music_idx = %s\"\"\"\n",
    "cursor.executemany(sql_query,top_emotion_data)\n",
    "indj_db.commit()\n",
    "\n",
    "sql_query2 = \"\"\"INSERT INTO RENEW_lyrics_emotion_percent\n",
    "    (music_idx , lov , joy , pas , hap , sad ,ang , lon , mis , fea , sup)\n",
    "    VALUES (%s , %s , %s , %s , %s , %s , %s, %s , %s, %s, %s)\"\"\"\n",
    "cursor.executemany(sql_query2,emotion_percent_data)\n",
    "indj_db.commit()\n",
    "\n",
    "#연결 해제\n",
    "indj_db.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
